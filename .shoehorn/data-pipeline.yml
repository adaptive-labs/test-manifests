schemaVersion: 1
service:
  id: data-pipeline
  name: Data Processing Pipeline
  type: service
owner:
  - type: team
    id: data-team
  - type: team
    id: ml-team
lifecycle: production
description: ETL pipeline for data ingestion, transformation, and feature engineering using Apache Airflow
tags:
  - data-engineering
  - etl
  - airflow
  - python
  - batch-processing
links:
  - name: Repository
    url: https://github.com/company/data-pipeline
  - name: Airflow UI
    url: https://airflow.company.com
  - name: Data Quality Dashboard
    url: https://datadog.company.com/data-quality
  - name: Pipeline Monitoring
    url: https://grafana.company.com/d/data-pipeline
  - name: Data Catalog
    url: https://datahub.company.com
  - name: Pipeline Documentation
    url: https://docs.company.com/data-pipeline
relations:
  - type: subscribes_to
    target: topic:user-events
    notes: User event stream processing
  - type: subscribes_to
    target: topic:analytics-computed
    notes: Analytics aggregations for ML features
  - type: subscribes_to
    target: topic:recommendation-events
    notes: Recommendation feedback loop
  - type: reads_from
    target: database:postgres-db
    notes: Raw data extraction for transformations
  - type: writes_to
    target: database:postgres-db
    notes: Processed features and aggregations
  - type: publishes_to
    target: topic:pipeline-events
    notes: Pipeline status and data quality metrics
  - type: via
    target: service:kafka-events
    notes: All event streaming via Kafka
  - type: deployed_to
    target: service:kubernetes-prod
    notes: Airflow workers on dedicated node pool
